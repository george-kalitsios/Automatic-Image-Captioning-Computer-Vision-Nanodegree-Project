# Project-Automatic-Image-Captioning

<br />

In this project, I design and train a CNN-RNN (Convolutional Neural Network - Recurrent Neural Network) model for automatically generating image captions. The network is trained on the [ Microsoft Common Objects in COntext (MS COCO) dataset ](http://cocodataset.org/#home). The image captioning model is displayed below :

<br />

![Test Image 9](https://github.com/george-kalitsios/Project-Automatic-Image-Captioning/blob/master/Images/encoder-decoder.png)

The project will be broken up into four Python notebooks :

**Notebook 0 : Loading and Visualizing the Coco Dataset**

**Notebook 1 : Setting up the Project and verify the Dataset and the Model**

**Notebook 2 : Training the CNN-RNN Model to predict the Caption**

**Notebook 3 : Validating the model and Do some fun with it**

<br />

**Generating Image Captions**

**Here are some predictions from my model.**

## Good results

## Not so good results

The Udacity repository for this project: [Project: Automatic Image Captioning](https://github.com/udacity/CVND---Image-Captioning-Project

